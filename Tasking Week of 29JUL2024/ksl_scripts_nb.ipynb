{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be3b9e87",
   "metadata": {},
   "source": [
    "<style>\n",
    "    .main-header {\n",
    "        font-family: Courier, monospace;\n",
    "        font-size: 96px; /* Increased font size */\n",
    "        text-align: center;\n",
    "        color: #00FF00;\n",
    "    }\n",
    "    .sub-header {\n",
    "        font-family: Courier, monospace;\n",
    "        font-size: 72px; /* Increased font size */\n",
    "        text-align: center;\n",
    "        color: #00FF00;\n",
    "    }\n",
    "    .cursor {\n",
    "        font-family: Courier, monospace;\n",
    "        font-size: 72px; /* Increased font size to match sub-header */\n",
    "        text-align: center;\n",
    "        color: #00FF00;\n",
    "        display: inline;\n",
    "        animation: blink 1s steps(2, start) infinite;\n",
    "    }\n",
    "    @keyframes blink {\n",
    "        to {\n",
    "            visibility: hidden;\n",
    "        }\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<div class=\"main-header\">\n",
    "    THOR - Site Script\n",
    "</div>\n",
    "<div class=\"sub-header\">\n",
    "    ksl.com<span class=\"cursor\">_</span>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a502086-b519-42f6-9d8c-d65fb9071561",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "In this section, we import the necessary libraries and modules required for scraping ksl.com. These imports include standard libraries for handling dates and times, data manipulation, regular expressions, numerical operations, JSON handling, and making HTTP requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c59588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests\n",
    "# !pip install beautifulsoup4\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a3980-7a66-4f66-ab3e-dac955f27742",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "\n",
    "\n",
    "# Setting pandas display options for better readability during debugging\n",
    "pd.set_option('display.max_columns', None)  # Display all columns in DataFrames\n",
    "pd.set_option('display.max_rows', None)     # Display all rows in DataFrames\n",
    "pd.options.mode.chained_assignment = None   # Disable warning for chained assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2f6df7-49d8-4064-b6a3-2ed0fd70bf7d",
   "metadata": {},
   "source": [
    "## All KSL Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f3fdf5-e8b0-4f54-8dd5-88fa2441c025",
   "metadata": {},
   "source": [
    "### Check If Account Is blocked or Suspended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d501843d-4922-46a4-b0e6-41e60e59af5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_proxy(session, ip, timeout=5):\n",
    "    \"\"\"\n",
    "    Check if the proxy is working by comparing the reported IP with the expected IP.\n",
    "\n",
    "    Args:\n",
    "        session (requests.Session): The session with the proxy set.\n",
    "        ip (str): The expected IP address of the proxy.\n",
    "        timeout (int, optional): The timeout for the request in seconds. Default is 5 seconds.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the proxy IP matches the reported IP, False otherwise.\n",
    "    \"\"\"\n",
    "    print('Function: check_proxy')\n",
    "\n",
    "\n",
    "    try:\n",
    "        response = session.get('https://icanhazip.com', timeout=timeout)\n",
    "        response.raise_for_status()  # Raises an HTTPError for bad responses\n",
    "        reported_ip = response.text.strip()\n",
    "        print(f'Successful response from icanhazip.com. Reported IP: {reported_ip}')\n",
    "    except requests.Timeout:\n",
    "        print(f'Timeout error: The request took longer than {timeout} seconds.')\n",
    "        reported_ip = ''\n",
    "    except requests.RequestException as e:\n",
    "        print(f'Error setting proxy or fetching IP: {e}')\n",
    "        reported_ip = ''\n",
    "\n",
    "    print(f'Proxy IP: {ip} - Reported IP: {reported_ip}')\n",
    "    return ip.strip() == reported_ip\n",
    "\n",
    "\n",
    "\n",
    "def check_blocked(session, timeout=5):\n",
    "    \"\"\"\n",
    "    Check if the IP is blocked by making a request to the KSL Cars API and analyzing the response.\n",
    "\n",
    "    Args:\n",
    "        session (requests.Session): The session with the proxy set.\n",
    "        timeout (int, optional): The timeout for the request in seconds. Default is 5 seconds.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing a boolean indicating if blocked (True) or not (False), and a dictionary with error details if blocked.\n",
    "    \"\"\"\n",
    "    print('Function: check_blocked')\n",
    "\n",
    "\n",
    "    checkpoint_data = {\n",
    "        \"ErrorName\": \"Blocked\",\n",
    "        \"ErrorTime\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        \"ErrorDescription\": \"Error loading search page\",\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = session.get('https://cars.ksl.com/nextjs-api/ip', timeout=timeout)\n",
    "        response.raise_for_status()  # Raises an HTTPError for bad responses\n",
    "    except requests.Timeout:\n",
    "        print(f'Timeout error: The request took longer than {timeout} seconds.')\n",
    "        checkpoint_data[\"ErrorDescription\"] = \"Timeout error while loading search page\"\n",
    "        return True, checkpoint_data\n",
    "    except requests.RequestException as e:\n",
    "        print(f'Error fetching IP: {e}')\n",
    "        return True, checkpoint_data\n",
    "\n",
    "    try:\n",
    "        data = json.loads(response.text)['data']['ipAddress']\n",
    "        print(f'Successful response from KSL Cars API. IP Address: {data}')\n",
    "    except (json.JSONDecodeError, KeyError) as e:\n",
    "        print(f'Error parsing response JSON: {e}')\n",
    "        return True, checkpoint_data\n",
    "\n",
    "    return False, {}\n",
    "\n",
    "###\n",
    "### Sites method for Checking If IP is Blocked\n",
    "### Could Be used to chech if blocked\n",
    "###\n",
    "# 'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\"\n",
    "\n",
    "# fetch(\"https://be.durationmedia.net/scriptloaded?siteId=11162\", {\n",
    "#   \"headers\": {\n",
    "#     \"accept\": \"*/*\",\n",
    "#     \"accept-language\": \"en-US,en;q=0.9\",\n",
    "#     \"cache-control\": \"no-cache\",\n",
    "#     \"pragma\": \"no-cache\",\n",
    "#     \"sec-ch-ua\": \"\\\"Not/A)Brand\\\";v=\\\"8\\\", \\\"Chromium\\\";v=\\\"126\\\", \\\"Google Chrome\\\";v=\\\"126\\\"\",\n",
    "#     \"sec-ch-ua-mobile\": \"?0\",\n",
    "#     \"sec-ch-ua-platform\": \"\\\"Windows\\\"\",\n",
    "#     \"sec-fetch-dest\": \"empty\",\n",
    "#     \"sec-fetch-mode\": \"cors\",\n",
    "#     \"sec-fetch-site\": \"cross-site\"\n",
    "#   },\n",
    "#   \"referrer\": \"https://cars.ksl.com/\",\n",
    "#   \"referrerPolicy\": \"strict-origin-when-cross-origin\",\n",
    "#   \"body\": null,\n",
    "#   \"method\": \"GET\",\n",
    "#   \"mode\": \"cors\",\n",
    "#   \"credentials\": \"omit\"\n",
    "# });"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba70d9d-acea-402f-b474-d91a932f1024",
   "metadata": {},
   "source": [
    "### KSL Searching Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc2e350-c000-425c-a66c-70b70e7e6754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSearchListings(session, search_terms, timeout=(5, 5), sleep_time=3, max_pages=10):\n",
    "    \"\"\"\n",
    "    Fetches car listings based on the given search terms from the specified API endpoint.\n",
    "\n",
    "    Args:\n",
    "        session: The requests session to be used for making HTTP requests.\n",
    "        search_terms (dict): Dictionary containing search parameters such as Make, Model, Min Year, Max Year, Max Miles, and Fuel Type.\n",
    "        timeout (tuple): Timeout settings for the HTTP requests (connect timeout, read timeout).\n",
    "        sleep_time (int): Time in seconds to sleep between requests to avoid rate limiting.\n",
    "        max_pages (int): Maximum number of pages to fetch.\n",
    "\n",
    "    Returns:\n",
    "        search_results (pd.DataFrame): DataFrame containing the search results.\n",
    "        errors (list): List of dictionaries containing error information.\n",
    "    \"\"\"\n",
    "    print('Function: GetSearchListings')\n",
    "\n",
    "\n",
    "    url = \"https://cars.ksl.com/nextjs-api/proxy?\"\n",
    "    \n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\",\n",
    "        \"accept\": \"*/*\",\n",
    "        \"accept-language\": \"en-US,en;q=0.9\",\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"priority\": \"u=1, i\",\n",
    "        \"sec-ch-ua\": \"\\\"Not/A)Brand\\\";v=\\\"8\\\", \\\"Chromium\\\";v=\\\"126\\\", \\\"Google Chrome\\\";v=\\\"126\\\"\",\n",
    "        \"sec-ch-ua-mobile\": \"?0\",\n",
    "        \"sec-ch-ua-platform\": \"\\\"Windows\\\"\",\n",
    "        \"sec-fetch-dest\": \"empty\",\n",
    "        \"sec-fetch-mode\": \"cors\",\n",
    "        \"sec-fetch-site\": \"same-origin\",\n",
    "        \"x-ddm-event-accept-language\": \"en-US\",\n",
    "        \"x-ddm-event-ip-address\": \"undefined\",\n",
    "        \"x-ddm-event-user-agent\": \"[object Object]\"\n",
    "    }\n",
    "\n",
    "    body = {\n",
    "        \"endpoint\": \"/classifieds/cars/search/searchByUrlParams\",\n",
    "        \"options\": {\n",
    "            \"method\": \"POST\",\n",
    "            \"headers\": {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"User-Agent\": \"cars-node\",\n",
    "                \"X-App-Source\": \"frontline\",\n",
    "                \"X-DDM-EVENT-USER-AGENT\": {\n",
    "                    \"ua\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\",\n",
    "                    \"browser\": {\n",
    "                        \"name\": \"Chrome\",\n",
    "                        \"version\": \"126.0.0.0\",\n",
    "                        \"major\": \"126\"\n",
    "                    },\n",
    "                    \"engine\": {\n",
    "                        \"name\": \"Blink\",\n",
    "                        \"version\": \"126.0.0.0\"\n",
    "                    },\n",
    "                    \"os\": {\n",
    "                        \"name\": \"Windows\",\n",
    "                        \"version\": \"10\"\n",
    "                    },\n",
    "                    \"device\": {},\n",
    "                    \"cpu\": {\n",
    "                        \"architecture\": \"amd64\"\n",
    "                    }\n",
    "                },\n",
    "                \"X-DDM-EVENT-ACCEPT-LANGUAGE\": \"en-US\",\n",
    "                \"X-MEMBER-ID\": None,\n",
    "                \"cookie\": \"\"\n",
    "            },\n",
    "            \"body\": []\n",
    "        }\n",
    "    }\n",
    "\n",
    "    page_num = 1\n",
    "    results_returned = 0\n",
    "    total_returned = 0\n",
    "    results_count = 1000\n",
    "    search_results = pd.DataFrame()\n",
    "    errors = []\n",
    "\n",
    "    while total_returned < results_count and page_num <= max_pages:\n",
    "\n",
    "        #Pagination and Search Terms\n",
    "        body['options']['body'] = [\n",
    "            \"perPage\", \"96\",\n",
    "            \"page\", str(page_num),\n",
    "            \"make\", search_terms['Make'],\n",
    "            \"model\", search_terms['Model'],\n",
    "            \"yearTo\", search_terms['Max Year'],\n",
    "            \"yearFrom\", search_terms['Min Year'],\n",
    "            \"mileageTo\", search_terms['Max Miles'],\n",
    "            \"fuel\", search_terms['Fuel Type'],\n",
    "            \"includeFacetCounts\", \"0\",\n",
    "            \"es_query_group\", None\n",
    "        ]\n",
    "        \n",
    "        # Check if 'Trim' exists in search_terms and is not None\n",
    "        if 'Trim' in search_terms and search_terms['Trim']:\n",
    "            # Find the index where 'model' is located\n",
    "            model_index = body['options']['body'].index(\"model\")\n",
    "            # Insert 'trim' and its value right after 'model' and its value\n",
    "            body['options']['body'][model_index + 2:model_index + 2] = [\"trim\", search_terms['Trim']]\n",
    "\n",
    "        try:\n",
    "            response = session.post(url, headers=headers, json=body, timeout=timeout)\n",
    "            response.raise_for_status()  # Raises an HTTPError for bad responses\n",
    "            print(f'Successful response for page {page_num}')\n",
    "        except requests.Timeout:\n",
    "            error_info = {\n",
    "                \"ErrorName\": \"Timeout\",\n",
    "                \"ErrorTime\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                \"ErrorDescription\": f'Timeout error on page {page_num}'\n",
    "            }\n",
    "            print(error_info[\"ErrorDescription\"])\n",
    "            errors.append(error_info)\n",
    "            break  # Exit loop on timeout\n",
    "        except requests.RequestException as e:\n",
    "            error_info = {\n",
    "                \"ErrorName\": \"RequestException\",\n",
    "                \"ErrorTime\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                \"ErrorDescription\": f'Error on page {page_num}: {e}'\n",
    "            }\n",
    "            print(error_info[\"ErrorDescription\"])\n",
    "            errors.append(error_info)\n",
    "            break  # Exit loop on request exception\n",
    "\n",
    "        try:\n",
    "            json_data = json.loads(response.text)\n",
    "            json_items = json_data['data']['items']\n",
    "            results_returned = len(json_items)\n",
    "            total_returned += results_returned\n",
    "            results_count = json_data['data']['count']\n",
    "            print(f'Page {page_num} Returned: {results_returned} Total: {total_returned} results so far out of {results_count} total.')\n",
    "        except (json.JSONDecodeError, KeyError) as e:\n",
    "            error_info = {\n",
    "                \"ErrorName\": \"JSONDecodeError\" if isinstance(e, json.JSONDecodeError) else \"KeyError\",\n",
    "                \"ErrorTime\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                \"ErrorDescription\": f'Error parsing response JSON on page {page_num}: {e}'\n",
    "            }\n",
    "            print(error_info[\"ErrorDescription\"])\n",
    "            errors.append(error_info)\n",
    "            break  # Exit loop on JSON error\n",
    "\n",
    "        search_results = pd.concat([search_results, pd.json_normalize(json_items)])\n",
    "\n",
    "        if not results_returned:\n",
    "            print('No results returned')\n",
    "            break # Exit loop on no results\n",
    "        elif total_returned < results_count:\n",
    "            page_num += 1\n",
    "            body['options']['body'][3] = str(page_num)\n",
    "            time.sleep(sleep_time) # Sleep only if there are more results\n",
    "\n",
    "    print(search_results.shape)\n",
    "    if not search_results.empty and 'id' in search_results.columns:\n",
    "        search_results.reset_index(drop=True, inplace=True)\n",
    "        search_results = search_results.drop_duplicates(subset='id')\n",
    "        print(search_results.shape)\n",
    "\n",
    "        search_url = search_terms['Search Url'] #'\"' + '\", \"'.join(body['options']['body']) + '\"'\n",
    "        search_results['thor_timestamp'] = int(time.time())\n",
    "        search_results['thor_website'] = \"ksl.com\"\n",
    "        search_results['thor_search_url'] = search_url\n",
    "        search_results['thor_full_listing_url'] = 'https://cars.ksl.com/listing/' + search_results['id'].astype(str)\n",
    "        search_results['thor_listing_url'] = 'https://cars.ksl.com/listing/' + search_results['id'].astype(str)\n",
    "        \n",
    "    return search_results, errors\n",
    "\n",
    "\n",
    "\n",
    "def GetListingDetails(session, listing_ids, timeout=(5, 5)):\n",
    "    \"\"\"\n",
    "    Fetches details for a list of car listings from the KSL Cars API.\n",
    "\n",
    "    Args:\n",
    "        session (requests.Session): The session object used to perform HTTP requests.\n",
    "        listing_ids (list): A list of listing IDs for which details are to be fetched.\n",
    "        timeout (tuple): A tuple specifying the connection and read timeout for the request.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - pd.DataFrame: A DataFrame with the details of the listings.\n",
    "            - list: A list of errors encountered during the process.\n",
    "\n",
    "    Raises:\n",
    "        requests.Timeout: If the request times out.\n",
    "        requests.RequestException: For any other request-related errors.\n",
    "        json.JSONDecodeError: If there is an error in decoding the JSON response.\n",
    "        KeyError: If the expected keys are not found in the response JSON.\n",
    "    \n",
    "    Notes:\n",
    "        The function sends a POST request to the KSL Cars API with the listing IDs in the request body.\n",
    "        It processes the response JSON to extract the listing details and normalize them into a DataFrame.\n",
    "        Any errors encountered during the request or JSON parsing are captured and returned in the errors list.\n",
    "        Additional standard fields are added to the resulting DataFrame.\n",
    "    \"\"\"\n",
    "    print('Function: GetListingDetails')\n",
    "\n",
    "    \n",
    "    errors = []\n",
    "    listing_details = pd.DataFrame()\n",
    "    json_items = []\n",
    "\n",
    "    url = \"https://cars.ksl.com/nextjs-api/cars-api\"\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\",\n",
    "        \"accept\": \"*/*\",\n",
    "        \"accept-language\": \"en-US,en;q=0.9\",\n",
    "        \"content-type\": \"text/plain;charset=UTF-8\",\n",
    "        \"priority\": \"u=1, i\",\n",
    "        \"sec-ch-ua\": \"\\\"Not/A)Brand\\\";v=\\\"8\\\", \\\"Chromium\\\";v=\\\"126\\\", \\\"Google Chrome\\\";v=\\\"126\\\"\",\n",
    "        \"sec-ch-ua-mobile\": \"?0\",\n",
    "        \"sec-ch-ua-platform\": \"\\\"Windows\\\"\",\n",
    "        \"sec-fetch-dest\": \"empty\",\n",
    "        \"sec-fetch-mode\": \"cors\",\n",
    "        \"sec-fetch-site\": \"same-origin\",\n",
    "        \"cookie\": (\"ddmDeviceId=4cayt4aocxik; __zlcmid=1JlmPjqmqsSCgGn; PHPSESSID=c6umt3leifcbc9uqmdo3dkstnh; kslPhotoViewerNewOldRollout=82; \"\n",
    "                \"kslInactiveSpecsRollout=34; kslUseNewFeaturedAdLayoutRollout=38; kslRentalRulesFlagRollout=99; \"\n",
    "                \"kslGeneralSelfServeTextVariantsRollout=71; kslGenElasticSearchRollout=16; kslGeneralShowImmediateRollout=22; \"\n",
    "                \"kslCarsBigQueryRollout=90; kslElasticSearch2Rollout=65; session_type=mongo; \"\n",
    "                \"mf_378954bf-e4e1-4ec3-b201-d1be116e57c4=||1719184063920||0||||0|0|58.90044; pxcts=6666a42d-31b5-11ef-a29f-5649a26cf9fd; \"\n",
    "                \"_pxvid=661ec623-31b5-11ef-a0e0-7a1142995b80; OTGPPConsent=DBABBg~BAAAAACA.QA; __ssid=3645285dec96aec382dbfc49a9b9a4f; \"\n",
    "                \"visitor_id911272=543911626; visitor_id911272-hash=ebcabbd596efb8e26587bc22e053b175b2641f9c5ad68c39d059fde66c78bb9404d33d010c9cfc6c50d723c929cec0fafc06fd3f; \"\n",
    "                \"__stripe_mid=efef22a5-5d7e-4993-9af5-b5846b1554d63de97b; OptanonAlertBoxClosed=2024-06-23T23:07:59.336Z; \"\n",
    "                \"ddmSessionId=a3qt6rmjb5kn; _pxhd=BFxro8Fys/KtNLq7EdOXCOOF9kJpb/OPegfL3iguuaNt9KQaprTOIpvUsC9xS8Pp/r5kpw0q1D8lpvOrMTqF1Q==:z9G/vdL7G0jMjYNERvO4GNwWf9/i0QiZumG4--3PktD9MMLCJwFX9gfd-TDfg7bBmH0-PZmxkUSFmF0lV0hIe6ng9LNjvwTFM6JbPNFCBYs=; \"\n",
    "                \"__stripe_sid=8184e90b-67ac-471e-815b-ca34a768fd1cb474d8; OptanonConsent=isGpcEnabled=0&datestamp=Sun+Jun+23+2024+22%3A52%3A14+GMT-0400+(Eastern+Daylight+Time)&version=202405.1.0&browserGpcFlag=0&isIABGlobal=false&hosts=&consentId=88fdf437-02c0-4110-8341-7927659c312a&interactionCount=1&isAnonUser=1&landingPath=NotLandingPage&GPPCookiesCount=1&groups=C0001%3A1%2CC0003%3A1%2CC0002%3A1%2CSSPD_BG%3A1%2CC0004%3A1&intType=3&geolocation=US%3BMO&AwaitingReconsent=false; \"\n",
    "                \"_px2=eyJ1IjoiYzJjZTkxNDAtMzFkNC0xMWVmLTljNzktYTE2ZjUxZmUxM2RlIiwidiI6IjY2MWVjNjIzLTMxYjUtMTFlZi1hMGUwLTdhMTE0Mjk5NWI4MCIsInQiOjE3MTkxOTc4MzU0MzksImgiOiI4NjhjZTMyYTNhZTIyZTBiNzNiNjNhYTkzMDEyYjg0ZDdlZTljNzllYTFjYjEzOTg5YzEyNzdhMDhiN2MxNWVjIn0=; \"\n",
    "                \"_ga=GA1.1.715650853.1719197760; _gcl_au=1.1.189562850.1719197761; _ga_JW89DL7T5D=GS1.1.1719197759.1.1.1719197760.59.0.0\"),\n",
    "        \"Referer\": \"https://cars.ksl.com/listing/9362104\",\n",
    "        \"Referrer-Policy\": \"strict-origin-when-cross-origin\"\n",
    "    }\n",
    "\n",
    "    body = {\n",
    "        \"endpoint\": \"/search\",\n",
    "        \"request\": {\n",
    "            \"method\": \"POST\",\n",
    "            \"body\": {\n",
    "                \"data\": {\n",
    "                    \"type\": \"search\",\n",
    "                    \"attributes\": {\n",
    "                        \"query\": {\n",
    "                            \"id\": listing_ids\n",
    "                        },\n",
    "                        \"nav\": {\n",
    "                            \"page\": 1,\n",
    "                            \"perPage\": len(listing_ids)\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = session.post(url, headers=headers, json=body)\n",
    "        response.raise_for_status()  # Raises an HTTPError for bad responses\n",
    "        print(f'Successful response for page')\n",
    "    except requests.Timeout:\n",
    "        error_info = {\n",
    "            \"ErrorName\": \"Timeout\",\n",
    "            \"ErrorTime\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            \"ErrorDescription\": f'Timeout error on page'\n",
    "        }\n",
    "        print(error_info[\"ErrorDescription\"])\n",
    "        errors.append(error_info)\n",
    "        return listing_details, errors\n",
    "    except requests.RequestException as e:\n",
    "        error_info = {\n",
    "            \"ErrorName\": \"RequestException\",\n",
    "            \"ErrorTime\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            \"ErrorDescription\": f'Error on page: {e}'\n",
    "        }\n",
    "        print(error_info[\"ErrorDescription\"])\n",
    "        errors.append(error_info)\n",
    "        return listing_details, errors\n",
    "\n",
    "    try:\n",
    "        json_data = json.loads(response.text)\n",
    "        json_items = json_data['data']\n",
    "        results_returned = len(json_items)\n",
    "        results_count = json_data['data']\n",
    "        print(f'Returned: {results_returned} out of {len(listing_ids)} total.')\n",
    "    except (json.JSONDecodeError, KeyError) as e:\n",
    "        error_info = {\n",
    "            \"ErrorName\": \"JSONDecodeError\" if isinstance(e, json.JSONDecodeError) else \"KeyError\",\n",
    "            \"ErrorTime\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            \"ErrorDescription\": f'Error parsing response JSON: {e}'\n",
    "        }\n",
    "        print(error_info[\"ErrorDescription\"])\n",
    "        errors.append(error_info)\n",
    "        return listing_details, errors\n",
    "\n",
    "    if len(json_items) and 'attributes' in json_items[0].keys():\n",
    "        flattened_data = [{**item['attributes']} for item in json_items]\n",
    "        listing_details = pd.json_normalize(flattened_data)\n",
    "        listing_details.reset_index(drop=True, inplace=True)\n",
    "        listing_details = listing_details.drop_duplicates(subset='id')\n",
    "        print(listing_details.shape)\n",
    "        \n",
    "        print('Adding standard fields to the DataFrame.')\n",
    "        listing_details['thor_timestamp'] = int(time.time())\n",
    "        listing_details['thor_website'] = \"ksl.com\"\n",
    "\n",
    "    return listing_details, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0db75c",
   "metadata": {},
   "source": [
    "## Standard Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5058e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FormatAggregator(ids, results, details, custom, source_key):\n",
    "    \"\"\"\n",
    "    Aggregates and formats data from multiple DataFrames based on provided IDs and source key mapping.\n",
    "\n",
    "    Parameters:\n",
    "    ids (list): List of IDs to iterate over and extract data for.\n",
    "    results (pd.DataFrame): DataFrame containing results data (not directly used in the function but assumed to be part of locals()).\n",
    "    details (pd.DataFrame): DataFrame containing details data (not directly used in the function but assumed to be part of locals()).\n",
    "    custom (pd.DataFrame): Default DataFrame to use if no specific DataFrame is mentioned in source_key.\n",
    "    source_key (dict): Dictionary mapping target DataFrame columns to source DataFrame columns. The key is the target column name, and the value is a dictionary with the source DataFrame name as key and source column name as value. If value is an empty dictionary, the target column will be filled with None.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with the aggregated and formatted data.\n",
    "    \n",
    "    Example:\n",
    "    source_key = {\n",
    "        'column1': {'results': 'source_column1'},\n",
    "        'column2': {'details': 'source_column2'},\n",
    "        'column3': {},  # This will be filled with None\n",
    "        'column4': 'custom',  # This will default to the custom DataFrame\n",
    "    }\n",
    "\n",
    "    Notes:\n",
    "    - The function assumes that the DataFrames (results, details) are present in the local scope.\n",
    "    - If a source column specified in source_key is not present in the corresponding DataFrame, the resulting column will be filled with None.\n",
    "    - The function concatenates the formatted data into a single DataFrame.\n",
    "    \"\"\"\n",
    "    print('Function: FormatAggregator')\n",
    "\n",
    "\n",
    "    # Create an empty DataFrame with columns from the keys of source_key\n",
    "    formatted_df = pd.DataFrame(columns=source_key.keys())\n",
    "    formatted_data = []\n",
    "    \n",
    "    # Iterate over each id\n",
    "    for id_ in ids:\n",
    "        row = {}\n",
    "        # Iterate over each key in source_key\n",
    "        for key, value in source_key.items():\n",
    "            if not value:  # If value is an empty dictionary\n",
    "                row[key] = value\n",
    "                continue\n",
    "            \n",
    "            if isinstance(value, dict):\n",
    "                # Extract the DataFrame and column name\n",
    "                df_name, column_name = list(value.items())[0]\n",
    "                df = locals().get(df_name)  # Get the DataFrame by its name\n",
    "                \n",
    "                if df is None or column_name not in df.columns:\n",
    "                    row[key] = None\n",
    "                else:\n",
    "                    # Extract the value from the DataFrame using the id\n",
    "                    match = df.loc[df['id'] == id_, column_name]\n",
    "                    row[key] = match.values[0] if not match.empty else None\n",
    "            else:\n",
    "                if key == 'id': # If id, use the current id\n",
    "                    row[key] = id_\n",
    "                else:\n",
    "                    # If the value is not a dictionary, use the provided value directly\n",
    "                    row[key] = value\n",
    "        \n",
    "        # Append the row to the formatted DataFrame\n",
    "        formatted_data.append(row)\n",
    "    \n",
    "    formatted_df = pd.concat([formatted_df, pd.DataFrame(formatted_data)])\n",
    "    \n",
    "    return formatted_df\n",
    "\n",
    "\n",
    "\n",
    "def Format_Output(current_task, current_user, search_results, listing_details, ids):\n",
    "    \"\"\"\n",
    "    Formats and aggregates output data for vehicle listings based on various input parameters.\n",
    "\n",
    "    Parameters:\n",
    "    - current_task (dict): Information about the current task, including task name and host.\n",
    "    - current_user (dict): Information about the current user, including account details.\n",
    "    - search_results (DataFrame): DataFrame containing search results with details such as URL, creation time, fuel type, etc.\n",
    "    - listing_details (DataFrame): DataFrame containing detailed information about listings, including photos, descriptions, and location.\n",
    "    - ids (list): List of IDs corresponding to the vehicle listings.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the following elements:\n",
    "        - search_results (DataFrame): The original search results DataFrame.\n",
    "        - listing_details (DataFrame): The original listing details DataFrame.\n",
    "        - Listings (DataFrame): Aggregated and formatted listings DataFrame.\n",
    "        - task_telemetry (DataFrame): DataFrame containing task telemetry information.\n",
    "        - user_telemetry (DataFrame): DataFrame containing user telemetry information.\n",
    "\n",
    "    Notes:\n",
    "    - The function uses a source key dictionary to map specific fields to their corresponding sources (custom, results, or details).\n",
    "    - It ensures required columns are present in the listing details before processing.\n",
    "    - Custom data is created by extracting and transforming specific fields such as images, title, and location.\n",
    "    - The final Listings DataFrame is generated using the FormatAggregator function.\n",
    "    - Task telemetry and user telemetry data are also created and returned as part of the output.\n",
    "    \"\"\"\n",
    "    print('Function: Format_Output')\n",
    "\n",
    "    \n",
    "    source_key = {\n",
    "        'title': {'custom': 'title'},\n",
    "        'id': 'id',\n",
    "        'link': {'results': 'thor_listing_url'},\n",
    "        'creation_time': {'results': 'createTime'},\n",
    "        'vehicle_condition': {'details': 'exteriorCondition'},\n",
    "        'vehicle_color': {'details': 'exteriorColor'},\n",
    "        'fuel_type': {'results': 'fuel'},\n",
    "        'paid_off': {'results': 'titleType'},\n",
    "        'make': {'results': 'make'},\n",
    "        'model': {'results': 'model'},\n",
    "        'year': {'results': 'makeYear'},\n",
    "        'number_owners': '',\n",
    "        'seller_type': {'results': 'sellerType'},\n",
    "        'vehicle_trim': {'results': 'trim'},\n",
    "        'vin': {'results': 'vin'},\n",
    "        'listing_photos': {'custom': 'images'},\n",
    "        'seller_name': {'results': 'firstName'},\n",
    "        'location': {'custom': 'location'},\n",
    "        'location_city': {'results': 'city'},\n",
    "        'location_state': {'results': 'state'},\n",
    "        'location_country': '',\n",
    "        'description': {'details': 'description'},\n",
    "        'price': {'results': 'price'},\n",
    "        'strikethrough_price': {'results': 'previousLowPrice'},\n",
    "        'odometer_unit': '',\n",
    "        'odometer_value': {'results': 'mileage'},\n",
    "        'thor_timestamp': {'results': 'thor_timestamp'},\n",
    "        'thor_website': \"ksl.com\",\n",
    "        'thor_mmr': False,\n",
    "        'thor_task': f\"{current_task}\",\n",
    "        'thor_user': f\"{current_user}\",\n",
    "        'Task': current_task['TaskName'],\n",
    "        'Host': current_task[\"Host\"],\n",
    "        'Account': current_user[\"AccountInfo\"][\"AccountID\"]\n",
    "    }\n",
    "\n",
    "    # Ensure 'id' and 'photo' are in the columns before proceeding\n",
    "    required_columns = ['id', 'photo', 'makeYear', 'make', 'model', 'trim', 'city', 'state']\n",
    "    if all(col in listing_details.columns for col in required_columns):\n",
    "        if not listing_details.empty:\n",
    "            custom_data = listing_details[['id', 'photo']].copy()\n",
    "            custom_data['images'] = custom_data['photo'].apply(\n",
    "                lambda photo_list: [photo['id'] for photo in photo_list] if isinstance(photo_list, list) else None\n",
    "            )\n",
    "            custom_data['title'] = (listing_details['makeYear'].astype(str) + ' ' + listing_details['make'] + ' ' + listing_details['model'] + ' ' + listing_details['trim']).str.strip()\n",
    "            custom_data['location'] = listing_details['city'] + \", \" + listing_details['state']\n",
    "        else:\n",
    "            custom_data = pd.DataFrame(columns=['id', 'photo', 'images', 'title'])\n",
    "    else:\n",
    "        custom_data = pd.DataFrame(columns=['id', 'photo', 'images', 'title'])\n",
    "\n",
    "    Listings = FormatAggregator(ids, search_results, listing_details, custom_data, source_key)\n",
    "\n",
    "\n",
    "    # Create task_telemetry/Will Be phased out\n",
    "    task_telemetry = Listings\n",
    "    \n",
    "    #Create user_telemetry\n",
    "    user_telemetry_data = {\n",
    "        \"TaskName\": current_task[\"TaskName\"],\n",
    "        \"Host\": current_task[\"Host\"],\n",
    "        \"AccountID\": current_user[\"AccountInfo\"][\"AccountID\"]\n",
    "    }\n",
    "\n",
    "    user_telemetry = pd.DataFrame([user_telemetry_data])\n",
    "\n",
    "    return search_results, listing_details, Listings, task_telemetry, user_telemetry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa0d7e8-6eb0-4863-a0f1-1593e90c42ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run Task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f488bbbb-b101-4f5c-82ed-2331f8d4d75e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Task_Run(driver, current_profile, current_task, current_user, results_check_callback, user_timer):\n",
    "    \"\"\"\n",
    "    Executes a task using the given parameters and handles session management, proxy settings, \n",
    "    and result processing.\n",
    "\n",
    "    Args:\n",
    "        driver (object): The driver used for performing tasks.\n",
    "        current_profile (dict): The current profile details.\n",
    "        current_task (dict): The current task details including search terms.\n",
    "        current_user (dict): Information about the current user including proxy details.\n",
    "        results_check_callback (function): Callback function to check and compare results.\n",
    "        user_timer (object): Timer object to track user account activity.\n",
    "\n",
    "    Yields:\n",
    "        tuple: A tuple containing the following elements:\n",
    "            - search_results (DataFrame): DataFrame containing search results.\n",
    "            - listing_details (DataFrame): DataFrame containing details of listings.\n",
    "            - Listings (list): List of processed listings.\n",
    "            - task_telemetry (dict): Dictionary containing task telemetry data.\n",
    "            - user_telemetry (dict): Dictionary containing user telemetry data.\n",
    "            - errors (dict): Dictionary containing error information if any issues are encountered.\n",
    "\n",
    "    The function performs the following steps:\n",
    "    1. Tracks how long the user account has been active using `user_timer.status()`.\n",
    "    2. Creates a session object with updated headers.\n",
    "    3. Configures the session to use a proxy if specified in `current_user`.\n",
    "    4. Checks if the session is blocked using `check_blocked` function.\n",
    "    5. If blocked, formats and yields the final results with errors.\n",
    "    6. Retrieves search listings using `GetSearchListings`.\n",
    "    7. Compares the search results with existing data using `results_check_callback`.\n",
    "    8. Retrieves details for new listings if any.\n",
    "    9. Formats and yields the final results including search results, listing details, \n",
    "       listings, task telemetry, user telemetry, and errors.\n",
    "    \"\"\"\n",
    "    print('Main Funtion: Task_Run')\n",
    "\n",
    "\n",
    "    #How to track how long the user account has been active\n",
    "    user_status = user_timer.status()\n",
    "    \n",
    "    # Create a session object\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\"\n",
    "    })\n",
    "\n",
    "    if current_user['ProxyInfo']['ProxyIp'] != '':\n",
    "        proxy = {\n",
    "            'http': current_user['ProxyInfo']['ProxyIp'] + ':' + current_user['ProxyInfo']['ProxyPort'],\n",
    "            'https':current_user['ProxyInfo']['ProxyIp'] + ':' + current_user['ProxyInfo']['ProxyPort']\n",
    "        }\n",
    "\n",
    "        # Configure the session to use the proxy\n",
    "        session.proxies.update(proxy)\n",
    "        proxy_set = check_proxy(session, current_user['ProxyInfo']['ProxyIp']) \n",
    "        \n",
    "        print('Proxy Set: ', proxy_set)\n",
    "    else:\n",
    "        proxy_set = True\n",
    "\n",
    "\n",
    "    #Check if Blocked\n",
    "    is_blocked, blocked_errors = check_blocked(session)\n",
    "    print(f\"is blocked: {is_blocked}\")\n",
    "    if is_blocked or proxy_set == False:\n",
    "        errors = {\"Disable\": True, \"error_data\": [blocked_errors]}   \n",
    "        print(errors)\n",
    "\n",
    "        final_results, final_details, Listings, task_telemetry, user_telemetry = Format_Output(current_task, current_user, pd.DataFrame(), pd.DataFrame(), [])\n",
    "        yield final_results, final_details, Listings, task_telemetry, user_telemetry, errors\n",
    "        return\n",
    "\n",
    "\n",
    "    search_results, errors = GetSearchListings(session, current_task['SearchTerms'], sleep_time=3)\n",
    "    print(errors)\n",
    "\n",
    "    # Check For New Listings\n",
    "    print(f\"****************COMPARE DB****************** {len(search_results)} Results\")\n",
    "    compare_columns = {\n",
    "        'id': 'id',\n",
    "    }\n",
    "    new_results = results_check_callback(search_results, 'ksl.com', compare_columns)\n",
    "    print(f\"****************COMPARE DB Complete****************** {len(new_results)} New\")\n",
    "\n",
    "    #get list of new IDs and ensure no blanks or duplicates\n",
    "    new_ids = new_results['id'].to_list()\n",
    "    new_ids = [*{item for item in new_ids if item}]\n",
    "\n",
    "    #Get listing Details\n",
    "    if len(new_results) > 0:\n",
    "        listing_details, errors = GetListingDetails(session, new_ids)\n",
    "    else:\n",
    "        listing_details = pd.DataFrame()\n",
    "        \n",
    "    #Format standard Output\n",
    "    search_results, listing_details, Listings, task_telemetry, user_telemetry = Format_Output(current_task, current_user,  search_results, listing_details, new_ids)\n",
    "\n",
    "    print(f\"{len(search_results)} search_results\")\n",
    "    print(f\"{len(listing_details)} listing_details\")\n",
    "    print(f\"{len(Listings)} Listings\")\n",
    "    print(f\"{len(task_telemetry)} task_telemetry\")\n",
    "    print(f\"{len(user_telemetry)} user_telemetry\")\n",
    "    print(f\"{errors} errors\")\n",
    "    errors = {}\n",
    "    \n",
    "    yield search_results, listing_details, Listings, task_telemetry, user_telemetry, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4325336e-2ef9-4615-af6e-6f9f6a853a21",
   "metadata": {},
   "source": [
    "## Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d73174-126c-45ff-a186-06258407684a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def results_check(data, website, columns_map):\n",
    "#     new_rows = data#[:1]#pd.DataFrame(columns=data.columns)\n",
    "#     return new_rows\n",
    "\n",
    "# class ProcessTimer:\n",
    "#     def __init__(self):\n",
    "#         self.start_time = time.time()\n",
    "#         print(f\"Process started at {self._format_time(self.start_time)}\")\n",
    "\n",
    "#     def finish(self):\n",
    "#         self.end_time = time.time()\n",
    "#         active_time = self.end_time - self.start_time\n",
    "#         result = {\n",
    "#             'start_time': self._format_time(self.start_time),\n",
    "#             'end_time': self._format_time(self.end_time),\n",
    "#             'active_time': str(timedelta(seconds=active_time))\n",
    "#         }\n",
    "#         return result\n",
    "\n",
    "#     def status(self):\n",
    "#         current_time = time.time()\n",
    "#         active_time = current_time - self.start_time\n",
    "#         return str(timedelta(seconds=active_time))\n",
    "\n",
    "#     def _format_time(self, timestamp):\n",
    "#         return datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    \n",
    "    \n",
    "# # App Settings\n",
    "# app_settings = {\n",
    "#     'UserProfilesPath': r'User Profiles',\n",
    "#     'PluginsPath': r'Plugins',\n",
    "#     'WebRtcName': 'WebRTC',\n",
    "#     'DefaultBrowserArgs': [\n",
    "#          '--disable-gpu',\n",
    "#          '--disable-software-rasterizer'\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "\n",
    "# current_user = {\n",
    "#     \"Host\": \"Bot-Host-0\",\n",
    "#     \"ProfileName\": \"ksl\",\n",
    "#     \"CheckedOut\": True,\n",
    "#     \"ProxyInfo\": {\n",
    "#         \"ProxyIp\": \"\",\n",
    "#         \"ProxyPort\": \"\",\n",
    "#         \"ProxyUsername\": \"\",\n",
    "#         \"ProxyPassword\": \"\",\n",
    "#         \"Description\": \"\",\n",
    "#     },\n",
    "#     \"BrowserInfo\": {\n",
    "#         \"BrowserType\": \"None\",\n",
    "#         \"UserFolderName\": \"kslTest\",\n",
    "#         \"Args\": ['--disable-notifications'],\n",
    "#         \"Extensions\": [],\n",
    "#         \"Cookies\": [],\n",
    "#         \"UserAgent\": \"\",\n",
    "#         \"WindowMaximized\": False,\n",
    "#         \"WindowWidth\": 0,\n",
    "#         \"WindowHight\": 0,\n",
    "#         \"ClearCookies\": False,\n",
    "#         \"Incognito\": False,\n",
    "#         \"Description\": \"\"\n",
    "#     },\n",
    "#     \"AccountInfo\": {\n",
    "#         \"AccountID\": \"kslTest\",\n",
    "#         \"AccountSite\": \"ksl.com\",\n",
    "#         \"ProfileURL\": \"\",\n",
    "#         \"UserName\": \"\",\n",
    "#         \"AltUserName\": \"\",\n",
    "#         \"Password\": \"\",\n",
    "#         \"MFAKey\": \"\",\n",
    "#         \"OtherData\": {},\n",
    "#         \"Description\": \"\"\n",
    "#     },\n",
    "#     \"Usage\": {\n",
    "#         \"LastActive\": \"0001-01-01T00:00:00\",\n",
    "#         \"ActiveTime\": \"00:00:00\",\n",
    "#         \"MaxActiveTime\": \"00:20:00\",\n",
    "#         \"MinCoolDownTime\": \"01:00:00\"\n",
    "#     }\n",
    "# }\n",
    "\n",
    "\n",
    "# current_task =  {\n",
    "#     'Host': 'Bot-Host-0',\n",
    "#     'Website': 'ksl.com',\n",
    "#     'ScriptName': 'Task_Run',\n",
    "#     'ProfileName': 'ksl',\n",
    "#     'TaskName': 'GMC Sierra 3500HD Crew',\n",
    "#     'Description': 'GMC Sierra (2004 - 2007) (130,000 Miles)',\n",
    "#     'Schedule': {\n",
    "#         'DailyEndTime': '23:59:59',\n",
    "#         'Interval': '00:50:00',\n",
    "#         'DailyStartTime': '00:48:00',\n",
    "#         'HitTimes': [],\n",
    "#         'IsActive': True\n",
    "#     },\n",
    "#     'SearchTerms': {\n",
    "#         'Max Miles': '140000',\n",
    "#         'Min Year': '1989',\n",
    "#         'Max Year': '2009',\n",
    "#         'Model': 'F-250;F-250 Super Duty;F-350;F-350 Super Duty;Excursion;Silverado 2500;Silverado 2500HD;Silverado 3500;Silverado 3500 CC Classic;Silverado 3500HD;Silverado 3500HD CC;D Series;D/W Series;Ram 2500;Ram 3500;Ram Pickup 2500;Ram Pickup 3500;Sierra 2500 Classic;Sierra 3500 CC Classic;Sierra 3500HD CC',\n",
    "#         'Fuel Type': 'Diesel;Bio-Diesel',\n",
    "#         'Make': 'Ford;Chevrolet;Dodge;GMC',\n",
    "#         # 'Trim': 'Trackhawk',\n",
    "#         'Search Url': \"https://cars.ksl.com/search/make/Ford;Chevrolet;Dodge;GMC/model/F-250;F-250+Super+Duty;F-350;F-350+Super+Duty;Excursion;Silverado+2500;Silverado+2500HD;Silverado+3500;Silverado+3500+CC+Classic;Silverado+3500HD;Silverado+3500HD+CC;D+Series;D%7CW+Series;Ram+2500;Ram+3500;Ram+Pickup+2500;Ram+Pickup+3500;Sierra+2500+Classic;Sierra+3500+CC+Classic;Sierra+3500HD+CC/yearFrom/1989/yearTo/2009/mileageTo/140000/fuel/Diesel;Bio-Diesel/sort/0\"\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# current_profile = {\n",
    "#     \"Hosts\": [\"Bot-Host-0\"],\n",
    "#     \"ProfileName\": 'ksl',\n",
    "#     \"Website\": 'facekslbook.com',\n",
    "#     \"Script\": \"ksl_scripts\",\n",
    "#     \"Description\": \"Master Profile For KSL\"\n",
    "# }  \n",
    "    \n",
    "    \n",
    "# ddd = ProcessTimer()\n",
    "# for final_results, final_details, Listings, task_telemetry, user_telemetry, errors in Task_Run(None, current_profile, current_task, current_user, results_check, ddd):\n",
    "#     print('final_results')\n",
    "#     display(final_results)\n",
    "#     print('final_details')\n",
    "#     display(final_details)\n",
    "#     print('Listings')\n",
    "#     display(Listings)\n",
    "#     print('task_telemetry')\n",
    "#     display(task_telemetry)\n",
    "#     print('user_telemetry')\n",
    "#     display(user_telemetry)\n",
    "#     print('errors')\n",
    "#     print(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ef6f2e",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708beffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a session object\n",
    "# session = requests.Session()\n",
    "# session.headers.update({\n",
    "#     \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\"\n",
    "# })\n",
    "\n",
    "# if current_user['ProxyInfo']['ProxyIp'] != '':\n",
    "#     proxy = {\n",
    "#         'http': current_user['ProxyInfo']['ProxyIp'] + ':' + current_user['ProxyInfo']['ProxyPort'],\n",
    "#         'https':current_user['ProxyInfo']['ProxyIp'] + ':' + current_user['ProxyInfo']['ProxyPort']\n",
    "#     }\n",
    "\n",
    "#     # Configure the session to use the proxy\n",
    "#     session.proxies.update(proxy)\n",
    "#     proxy_set = check_proxy(session, current_user['ProxyInfo']['ProxyIp']) \n",
    "    \n",
    "#     print('Proxy Set: ', proxy_set)\n",
    "# else:\n",
    "#     proxy_set = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# url = \"https://cars.ksl.com/nextjs-api/proxy?\"\n",
    "\n",
    "# headers = {\n",
    "#     \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\",\n",
    "#     \"accept\": \"*/*\",\n",
    "#     \"accept-language\": \"en-US,en;q=0.9\",\n",
    "#     \"content-type\": \"application/json\",\n",
    "#     \"priority\": \"u=1, i\",\n",
    "#     \"sec-ch-ua\": \"\\\"Not/A)Brand\\\";v=\\\"8\\\", \\\"Chromium\\\";v=\\\"126\\\", \\\"Google Chrome\\\";v=\\\"126\\\"\",\n",
    "#     \"sec-ch-ua-mobile\": \"?0\",\n",
    "#     \"sec-ch-ua-platform\": \"\\\"Windows\\\"\",\n",
    "#     \"sec-fetch-dest\": \"empty\",\n",
    "#     \"sec-fetch-mode\": \"cors\",\n",
    "#     \"sec-fetch-site\": \"same-origin\",\n",
    "#     \"x-ddm-event-accept-language\": \"en-US\",\n",
    "#     \"x-ddm-event-ip-address\": \"undefined\",\n",
    "#     \"x-ddm-event-user-agent\": \"[object Object]\"\n",
    "# }\n",
    "\n",
    "# body = {\n",
    "#     \"endpoint\": \"/classifieds/cars/search/searchByUrlParams\",\n",
    "#     \"options\": {\n",
    "#         \"method\": \"POST\",\n",
    "#         \"headers\": {\n",
    "#             \"Content-Type\": \"application/json\",\n",
    "#             \"User-Agent\": \"cars-node\",\n",
    "#             \"X-App-Source\": \"frontline\",\n",
    "#             \"X-DDM-EVENT-USER-AGENT\": {\n",
    "#                 \"ua\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\",\n",
    "#                 \"browser\": {\n",
    "#                     \"name\": \"Chrome\",\n",
    "#                     \"version\": \"126.0.0.0\",\n",
    "#                     \"major\": \"126\"\n",
    "#                 },\n",
    "#                 \"engine\": {\n",
    "#                     \"name\": \"Blink\",\n",
    "#                     \"version\": \"126.0.0.0\"\n",
    "#                 },\n",
    "#                 \"os\": {\n",
    "#                     \"name\": \"Windows\",\n",
    "#                     \"version\": \"10\"\n",
    "#                 },\n",
    "#                 \"device\": {},\n",
    "#                 \"cpu\": {\n",
    "#                     \"architecture\": \"amd64\"\n",
    "#                 }\n",
    "#             },\n",
    "#             \"X-DDM-EVENT-ACCEPT-LANGUAGE\": \"en-US\",\n",
    "#             \"X-MEMBER-ID\": None,\n",
    "#             \"cookie\": \"\"\n",
    "#         },\n",
    "#         \"body\": []\n",
    "#     }\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "# #Pagination and Search Terms\n",
    "# body['options']['body'] = [\n",
    "#     \"perPage\", \"96\",\n",
    "#     \"page\", str(page_num),\n",
    "#     \"make\", search_terms['Make'],\n",
    "#     \"model\", search_terms['Model'],\n",
    "#     \"trim\", search_terms['Trim'],\n",
    "#     \"yearTo\", search_terms['Max Year'],\n",
    "#     \"yearFrom\", search_terms['Min Year'],\n",
    "#     \"mileageTo\", search_terms['Max Miles'],\n",
    "#     \"fuel\", search_terms['Fuel Type'],\n",
    "#     \"includeFacetCounts\", \"0\",\n",
    "#     \"es_query_group\", None\n",
    "# ]\n",
    "\n",
    "# try:\n",
    "#     response = session.post(url, headers=headers, json=body, timeout=timeout)\n",
    "#     response.raise_for_status()  # Raises an HTTPError for bad responses\n",
    "#     print(f'Successful response for page {page_num}')\n",
    "# except requests.Timeout:\n",
    "#     error_info = {\n",
    "#         \"ErrorName\": \"Timeout\",\n",
    "#         \"ErrorTime\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "#         \"ErrorDescription\": f'Timeout error on page {page_num}'\n",
    "#     }\n",
    "#     print(error_info[\"ErrorDescription\"])\n",
    "#     errors.append(error_info)\n",
    "#     break  # Exit loop on timeout\n",
    "# except requests.RequestException as e:\n",
    "#     error_info = {\n",
    "#         \"ErrorName\": \"RequestException\",\n",
    "#         \"ErrorTime\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "#         \"ErrorDescription\": f'Error on page {page_num}: {e}'\n",
    "#     }\n",
    "#     print(error_info[\"ErrorDescription\"])\n",
    "#     errors.append(error_info)\n",
    "#     break  # Exit loop on request exception\n",
    "\n",
    "# try:\n",
    "#     json_data = json.loads(response.text)\n",
    "#     json_items = json_data['data']['items']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
